version: '3.8'

services:
  # PostgreSQL Master Database
  kong-database-master:
    image: postgres:13
    container_name: kong-database-master
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_REPLICATION_USER: ${POSTGRES_REPLICATION_USER}
      POSTGRES_REPLICATION_PASSWORD: ${POSTGRES_REPLICATION_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - postgres-master-data:/var/lib/postgresql/data
      - postgres-wal-archive:/var/lib/postgresql/wal_archive
      - ../../config/postgresql/master/postgresql.conf:/etc/postgresql/postgresql.conf:ro
      - ../../config/postgresql/master/pg_hba.conf:/etc/postgresql/pg_hba.conf:ro
      - ../../scripts/postgresql/init-replication.sql:/docker-entrypoint-initdb.d/init-replication.sql:ro
    command: >
      postgres
      -c config_file=/etc/postgresql/postgresql.conf
      -c hba_file=/etc/postgresql/pg_hba.conf
    networks:
      - kong-net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped

  # PostgreSQL Slave Database
  kong-database-slave:
    image: postgres:13
    container_name: kong-database-slave
    environment:
      PGUSER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_MASTER_SERVICE: kong-database-master
      POSTGRES_REPLICATION_USER: ${POSTGRES_REPLICATION_USER}
      POSTGRES_REPLICATION_PASSWORD: ${POSTGRES_REPLICATION_PASSWORD}
    ports:
      - "5433:5432"
    volumes:
      - postgres-slave-data:/var/lib/postgresql/data
      - postgres-wal-archive:/var/lib/postgresql/wal_archive
      - ../../config/postgresql/slave/postgresql.conf:/etc/postgresql/postgresql.conf:ro
      - ../../config/postgresql/slave/pg_hba.conf:/etc/postgresql/pg_hba.conf:ro
      - ../../scripts/postgresql/setup-slave.sh:/setup-slave.sh:ro
    command: >
      bash -c "
      if [ ! -s /var/lib/postgresql/data/PG_VERSION ]; then
        echo 'Initializing slave from master...';
        rm -rf /var/lib/postgresql/data/*;
        PGPASSWORD='${POSTGRES_REPLICATION_PASSWORD}' pg_basebackup -h kong-database-master -p 5432 -U ${POSTGRES_REPLICATION_USER} -D /var/lib/postgresql/data -Fp -Xs -P -R -v;
        touch /var/lib/postgresql/data/standby.signal;
        echo \"primary_conninfo = 'host=kong-database-master port=5432 user=${POSTGRES_REPLICATION_USER} password=${POSTGRES_REPLICATION_PASSWORD} application_name=slave1'\" >> /var/lib/postgresql/data/postgresql.auto.conf;
        echo \"primary_slot_name = 'slave1_slot'\" >> /var/lib/postgresql/data/postgresql.auto.conf;
        chown -R postgres:postgres /var/lib/postgresql/data;
        chmod 700 /var/lib/postgresql/data;
      fi;
      exec docker-entrypoint.sh postgres -c config_file=/etc/postgresql/postgresql.conf -c hba_file=/etc/postgresql/pg_hba.conf
      "
    networks:
      - kong-net
    depends_on:
      kong-database-master:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 180s
    restart: unless-stopped

  # Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch
    environment:
      - ES_JAVA_OPTS=${ES_JAVA_OPTS}
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
      - ../../deployments/monitoring/elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro
    networks:
      - kong-net
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped

  # Logstash
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: logstash
    ports:
      - "8080:8080"
    volumes:
      - ../../deployments/monitoring/logstash/kong-logs.conf:/usr/share/logstash/pipeline/kong-logs.conf:ro
      - ../../deployments/monitoring/logstash/kong-template.json:/usr/share/logstash/templates/kong-template.json:ro
    networks:
      - kong-net
    depends_on:
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9600 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    restart: unless-stopped

  # Kibana
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: kibana
    ports:
      - "5601:5601"
    volumes:
      - ../../deployments/monitoring/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml:ro
    networks:
      - kong-net
    depends_on:
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 180s
    restart: unless-stopped

  # Kong Gateway
  kong:
    image: kong:alpine
    container_name: kong
    environment:
      KONG_DATABASE: ${KONG_DATABASE}
      KONG_PG_HOST: ${KONG_PG_HOST}
      KONG_PG_PORT: ${KONG_PG_PORT}
      KONG_PG_USER: ${KONG_PG_USER}
      KONG_PG_PASSWORD: ${KONG_PG_PASSWORD}
      KONG_PG_DATABASE: ${KONG_PG_DATABASE}
      KONG_PROXY_ACCESS_LOG: ${KONG_PROXY_ACCESS_LOG}
      KONG_ADMIN_ACCESS_LOG: ${KONG_ADMIN_ACCESS_LOG}
      KONG_PROXY_ERROR_LOG: ${KONG_PROXY_ERROR_LOG}
      KONG_ADMIN_ERROR_LOG: ${KONG_ADMIN_ERROR_LOG}
      KONG_ADMIN_LISTEN: ${KONG_ADMIN_LISTEN}
      KONG_LOG_LEVEL: ${KONG_LOG_LEVEL}
      KONG_PLUGINS: bundled,http-log
    ports:
      - "8000:8000"
      - "8001:8001"
      - "8443:8443"
      - "8444:8444"
    volumes:
      - /home/nickyin/srv/apim/logs:/tmp/kong-logs
    networks:
      - kong-net
    depends_on:
      kong-database-master:
        condition: service_healthy
      logstash:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "kong health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    restart: unless-stopped

  # Kong Bootstrap (Database Migration)
  kong-migration:
    image: kong:alpine
    container_name: kong-migration
    environment:
      KONG_DATABASE: ${KONG_DATABASE}
      KONG_PG_HOST: ${KONG_PG_HOST}
      KONG_PG_PORT: ${KONG_PG_PORT}
      KONG_PG_USER: ${KONG_PG_USER}
      KONG_PG_PASSWORD: ${KONG_PG_PASSWORD}
      KONG_PG_DATABASE: ${KONG_PG_DATABASE}
    command: kong migrations bootstrap
    networks:
      - kong-net
    depends_on:
      kong-database-master:
        condition: service_healthy
    restart: "no"


  # Backup Service
  kong-backup:
    image: postgres:13
    container_name: kong-backup
    environment:
      KONG_PG_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      BACKUP_RETENTION_DAYS: ${BACKUP_RETENTION_DAYS}
      INCREMENTAL_RETENTION_DAYS: ${INCREMENTAL_RETENTION_DAYS}
    volumes:
      - backup-data:/srv/apim/database/backups
      - postgres-wal-archive:/srv/apim/database/wal_archive
      - ../../scripts/backup:/scripts:ro
    command: >
      bash -c "
      echo 'Backup service starting...';
      apt-get update && apt-get install -y cron;
      echo '0 2 * * * /scripts/full_backup.sh' > /tmp/crontab;
      echo '0 * * * * /scripts/incremental_backup.sh' >> /tmp/crontab;
      crontab /tmp/crontab;
      service cron start;
      echo 'Cron service started. Monitoring logs...';
      tail -f /dev/null
      "
    networks:
      - kong-net
    depends_on:
      kong-database-master:
        condition: service_healthy
    restart: unless-stopped

volumes:
  postgres-master-data:
    driver: local
  postgres-slave-data:
    driver: local
  postgres-wal-archive:
    driver: local
  backup-data:
    driver: local
  elasticsearch-data:
    driver: local

networks:
  kong-net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16